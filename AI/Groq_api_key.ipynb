{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import YoutubeLoader\n",
    "# from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from langchain.text_splitter import TokenTextSplitter, RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'c5dmmWl5jTY'}, page_content=\"imagine you're going to a very important party with your partner and you want to wear black shoes but your partner wants you to wear brown shoes instead how would you negotiate this situation many people believe that win-win or 50/50 is the best outcome in negotiation if you also think so then can you tell me what is the win-win in this example are you going to wear one black shoe and one brown shoe it sounds ridiculous right that is exactly how Chris Voss thinks he does not believe in win-wins Chris is the author of a New York Times best-selling book called Never split the difference negotiate as if your life depends on it Chris has worked for more than 20 years as a hostage negotiator at the FBI dealing with kidnappers bank robbers and extreme terrorists he found out that the knowledge he has learned as a hostage negotiator is also applicable to a wide range of business and personal life situations since the fundamentals of human negotiations are essentially the same in any situation regardless of age gender and ethnicity negotiation with a terrorist and negotiation with a businessman is based on the same principles we negotiate every day such as when you try to send the kids to bed early or when you convince a friend to go to a different restaurant our entire life is negotiation and Chris says that negotiation is not about your way or my way negotiation is about finding a third way that makes both sides happy happy for example let's say two of your kids are fighting over a chocolate and they cannot divide it it doesn't matter how you divide the chocolate they are both unhappy and think that the other side got more the Third Way solution in this situation is to ask one kid to divide the chocolate equally and the other kid to pick first in this video I will share with you the five lessons I learned from the book that will help you to become a better negotiator lesson number one understand first every negotiation begins with the universally applicable law that people want to be understood and accepted listening is the cheapest yet most effective thing we can do to get there by listening intensely you demonstrate empathy and a sincere desire to understand what the other side is experiencing it sounds easy but you cannot imagine how many people fail to listen when the other side starts talking instead of listening they think about what they will say and when the other side stops they give their pitch regardless of what the other side just said and the other side starts saying to himself huh they didn't even listen to a word I was saying I'm sure you've experienced this sometimes you talk to someone and you feel like you're talking about different topics people usually yell in negotiations because they feel that they have not been heard everyone wants three things in negotiation number one to be understood number two respected and only then get what they want from the negotiation if you fail at listening don't expect success from the negotiation lesson number two negotiation is not a battle it is a discovery people who view negotiation as a battle of arguments become overwhelmed by the voices in their heads but the truth is negotiation isn't a battle it's an act of Discovery the objective is to uncover what the other side wants is it money time respect recognition that's Etc in order to do that the author recommends several tactics the first one is simply smiling when you smile at someone it's like reaching out to their brain and switching on positivity light we are 31% smarter when we are in a positive state of mind which also means if we are in a negative state of mind it makes us 31% Dumber the second tactic is mirroring mirroring is simply repeating the last three or most critical words of what your opponent has just said for example your opponent I have a very high expectation and want more money you want more money mirroring feels very strange at first but if you practice it will work like magic mirroring makes the other side vomit information it's much more powerful than saying what did you mean by that when you say what did you mean by that you give your opponent a break to think and correct himself on the other side mirroring makes conversation run smoothly and makes the opponent reveal more information after you have mirrored stay silent for at least 4 seconds and let the mirroring do its magic lesson number three tactical empathy tactical empathy is understanding the feelings and mindset of the other person and hearing what is behind those feelings especially focusing on identifying the emotional obstacles that are standing in the way of agreement once you have identified the emotion then label it labeling simply means you summarize what your opponent just told you and give it back to him labels always start with it seems like it sounds like for example you see that your opponent talks very passionately about his students in order to label it you simply say it seems like you care a lot about your students then stay silent and let the label do its magic labeling is effective for two reasons first it helps you to confirm that you have identified the right emotion second it signals to your opponent that you truly understand him which creates a stronger Bond and makes your opponent like you if a person likes you it is six times more likely that you will have a deal empathy brings two brains together the moment you feel empathy and see that there is something that makes you collaborate with me then your brain power and my brain power get together to solve the problem another tactical empathy method is called called diffusing negatives with labels this is especially effective if you know that your opponent is angry and has bad feelings against you before you go to the meeting sit down and think about all the negative things that your opponent might say against you during the meeting or negotiation after you have identified all the negative feelings then label them for example let's say you know that your client is very unhappy because your company missed the deadline and didn't deliver what was promised based on this data you know that your client thinks that you are unreliable and unable to keep promises so as soon as you start the meeting you can diffuse the negative by saying it might seem like we're screwing you and we're not capable of keeping our promises and delivering what was agreed upon and because of this you might even consider not doing business with us anymore and you are absolutely right to think in this way the moment you say this your opponent thinks huh he thinks like I do I kind of like him if you did not diffuse the negative your opponent would spend hours explaining how bad he feels but now that you have diffused all the negatives your opponent will be more focused on the solution rather than complaining negative emotions and fear of losing affect our brain three times stronger than positive emotions so help your opponent to get rid of the negative feelings then you will have much better results lesson number four start with no pushing hard for a yes doesn't get you any closer to a victory contrary to popular belief no is the start of the negotiation not the end of it when you say yes to something you feel committed or trapped for example if I come to you and say can we talk for 5 minutes after you say yes automatically your brain starts saying how long is 5 minutes actually going to be am I going to be stuck with her for 1 hour and go home late is she going to sell me her stupid idea again all those distractions in your mind stop you from focusing on the negotiation you just want to get out of there as soon as possible in comparison to pushing you for yes if I came to you and said is it a bad time to talk for 5 minutes you'd probably say no it's not but let me finish X Y and Z and meet you in 15 minutes at my desk since you started with no you feel safe because you didn't commit to anything plus saying no gives control to you it was you who said let's meet in 15 minutes when you feel in control it makes you think quicker faster and helps you to focus on implementation without any distractions also after you said no you answered two to three upcoming questions by yourself I did not have to ask you where to meet when to meet you gave me everything I wanted without even working for it lesson number five that's right that is right is one of the the most powerful phrases in negotiation that you want to hear to get this answer you simply take your opponent's words and repeat back to him it sounds simple and maybe a stupid thing to do but works well it puts the other side's empathy on steroids if you get that is right then you can be sure that the deal is almost done that's right is what we say when we feel completely heard and believe that the other side really understands us we also say that is right at aha moments please be careful if you get you are right it means you failed completely the difference between these two phrases is Tiny But the implication is huge when somebody says you're right they're most likely trying to get rid of you or end the conversation dealing with people is one of the hardest jobs out there you can be perfect at your job but if you have poor people skills it's highly likely that you will have a a tough time at work if you want to improve your people skills then check out the video you see on your screen thanks for watching and have a wonderful day\")]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import YoutubeLoader\n",
    "\n",
    "YoutubeLoader.from_youtube_url(youtube_url=\"https://youtu.be/c5dmmWl5jTY?si=lIYHlpcbKzKYn4Q3\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'c:\\\\Users\\\\HP\\\\OneDrive\\\\Documents\\\\Books\\\\The Art of Being ALONE Solitude Is My HOME, Loneliness Was My Cage.pdf', 'page': 1}, page_content='The Art of Being Alone\\nSolitude is my Home\\nLoneliness was my Cage\\nRenuka Gavrani'),\n",
       " Document(metadata={'source': 'c:\\\\Users\\\\HP\\\\OneDrive\\\\Documents\\\\Books\\\\The Art of Being ALONE Solitude Is My HOME, Loneliness Was My Cage.pdf', 'page': 2}, page_content='Copyright ¬© 2023 R enuk a Gavrani All rights r eserved\\nNo part of this book may be r eproduced, or stor ed in a\\nretrieval system, or transmitted in any for m or by any\\nmeans, electr onic, mechanical, photocopying, r ecording, or\\notherwise, without e xpress written per mission of the author .')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader_new = PyPDFLoader(file_path=r\"c:\\Users\\HP\\OneDrive\\Documents\\Books\\The Art of Being ALONE Solitude Is My HOME, Loneliness Was My Cage.pdf\")\n",
    "data_new = loader_new.load()\n",
    "\n",
    "splitter_new = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=200)\n",
    "chunks_new = splitter_new.split_documents(data_new)\n",
    "chunks_new[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(file_path=r\"c:\\Users\\HP\\OneDrive\\Documents\\pdfs\\Muhammd_Saad.pdf\")\n",
    "data  = loader.load() # you should have a documnent of list here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'c:\\\\Users\\\\HP\\\\OneDrive\\\\Documents\\\\pdfs\\\\Muhammd_Saad.pdf', 'page': 0}, page_content='Muhammad Saad   \\nRawalpindi, Pakistan  \\nüìû +92-315-3716651 ‚úâÔ∏è rsaad0067@gmail.com   üîó https://www.linkedin.com/in/muhammad -saad -\\n24b20b253/  üêô https://github.com/MuhammadSaad -dotcom/projects  \\n    \\nSummary    \\n    \\n    \\nResults -oriented and highly motivated Bachelor o f Science in Computer Science candidate at Arid University, \\nspecializing in cutting -edge technologies such as Machine Learning , Deep learning and Natural Language Processing \\n(NLP)  adding with Html , CSS and JavaS cript .   \\nAdept at advanced coding, possessing strong analytical skills, and effective communication in English. Eager to \\ncontribute technical expertise and innovative solutions to the field of  artificial  Intelligence . \\n \\n Education     \\n    \\nArid  Univestry (BIIT) | Islamabad, Pakistan                                                                  Jan 2023 ‚Äì present    \\nBachelor Of Science in Computer Science  \\nGraduation: (July 2026 ) \\n   \\n‚óè Predicted Grade: First Class  \\n‚óè Current CG PA: 3.92/4.0   \\n‚óè Current Semester: 4 th \\n   \\nTechnical Skills    \\n \\n‚óè Programming Languages: Python, Java, C++, C , C#.net framework  (Frontend , \\nBackend ), Html , CSS, Java Script  \\n‚óè Technologies: Machine Learning , Dee p Learning , Natural Language Processing \\n(NLP)   \\n \\nPROJECTS     \\n \\nAs part of my dissertation, I have undertaken and successfully completed several projects \\nthat demonstrate my proficiency in various programming languages, frameworks, and \\nmachine learning models. These projects include:  \\n '),\n",
       " Document(metadata={'source': 'c:\\\\Users\\\\HP\\\\OneDrive\\\\Documents\\\\pdfs\\\\Muhammd_Saad.pdf', 'page': 1}, page_content=' \\n‚Ä¢ Real -Time Hand Sign Detection Model  \\nCreated a real -time hand sign detection model utilizing the YOLO (You Only Look Once) \\nalgorithm. This project focused on developing an accurate and responsive system for \\nrecognizing hand gestures in real -time, which can be applied in various assistive \\ntech nologies.  \\n‚Ä¢ Handwritten Image Classification Neural Network Model  \\nBuilt a neural network model for classifying handwritten images. This project involved \\npre-processing image data, designing and training the neural network, and achieving \\nhigh accuracy in recognizing handwritten digits and letters.  \\n‚Ä¢ Afzal Electronic Store Application  \\nDeveloped an electronic store application using the C#.NET framework. This project \\ninvolved designing a user -friendly interface, implementing secure payment systems, and \\nintegrating database management for efficient inventory tracking.  \\n‚Ä¢ Car Rental System  \\nDesigned and implemented a car rental system using Java. This project included the \\ndevelopment of a comprehensive booking system, user authentication, vehicle tracking, \\nand maintenance scheduling features, ensuring a seamless user experience.  \\n‚Ä¢ Neural Network Model Using Plain Python  \\nDeveloped a complete neural network model from scratch using plain Python. This \\nproject emphasized understanding the fundamental workings of neural networks, \\nincluding forward propagation, backpropagation, and gradient descent, without relying \\non high -level libraries.  \\nThese projects have not only enhanced my technical skills but also provided me with \\nvaluable experience in problem -solving, project management, and the application of \\ntheoretical knowledge to practical scenarios.  \\n    \\nACHIEVEMENTS  \\n    \\n‚óè Top Achiever Grant  for outstanding academic performance (2022 -2023)  \\n‚óè Got Invited to Telenor H Q | Gulberg Islamabad  for Amazing WorkS hop \\n ')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'c:\\\\Users\\\\HP\\\\OneDrive\\\\Documents\\\\pdfs\\\\Muhammd_Saad.pdf', 'page': 0}, page_content='Muhammad Saad   \\nRawalpindi, Pakistan  \\nüìû +92-315-3716651 ‚úâÔ∏è rsaad0067@gmail.com   üîó https://www.linkedin.com/in/muhammad -saad -\\n24b20b253/  üêô https://github.com/MuhammadSaad -dotcom/projects  \\n    \\nSummary    \\n    \\n    \\nResults -oriented and highly motivated Bachelor o f Science in Computer Science candidate at Arid University,'),\n",
       " Document(metadata={'source': 'c:\\\\Users\\\\HP\\\\OneDrive\\\\Documents\\\\pdfs\\\\Muhammd_Saad.pdf', 'page': 0}, page_content='specializing in cutting -edge technologies such as Machine Learning , Deep learning and Natural Language Processing \\n(NLP)  adding with Html , CSS and JavaS cript .   \\nAdept at advanced coding, possessing strong analytical skills, and effective communication in English. Eager to \\ncontribute technical expertise and innovative solutions to the field of  artificial  Intelligence . \\n \\n Education'),\n",
       " Document(metadata={'source': 'c:\\\\Users\\\\HP\\\\OneDrive\\\\Documents\\\\pdfs\\\\Muhammd_Saad.pdf', 'page': 0}, page_content='Education     \\n    \\nArid  Univestry (BIIT) | Islamabad, Pakistan                                                                  Jan 2023 ‚Äì present    \\nBachelor Of Science in Computer Science  \\nGraduation: (July 2026 ) \\n   \\n‚óè Predicted Grade: First Class  \\n‚óè Current CG PA: 3.92/4.0   \\n‚óè Current Semester: 4 th \\n   \\nTechnical Skills')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=20)\n",
    "chunks = splitter.split_documents(data)\n",
    "chunks[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\n",
    "for page in data:\n",
    "    text += page.page_content +\"\\n\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Muhammad Saad   \\nRawalpindi, Pakistan  \\nüìû +92-315-3716651 ‚úâÔ∏è rsaad0067@gmail.com   üîó https://www.linkedin.com/in/muhammad -saad -\\n24b20b253/  üêô https://github.com/MuhammadSaad -dotcom/projects  \\n    \\nSummary    \\n    \\n    \\nResults -oriented and highly motivated Bachelor o f Science in Computer Science candidate at Arid University, \\nspecializing in cutting -edge technologies such as Machine Learning , Deep learning and Natural Language Processing \\n(NLP)  adding with Html , CSS and JavaS cript .   \\nAdept at advanced coding, possessing strong analytical skills, and effective communication in English. Eager to \\ncontribute technical expertise and innovative solutions to the field of  artificial  Intelligence . \\n \\n Education     \\n    \\nArid  Univestry (BIIT) | Islamabad, Pakistan                                                                  Jan 2023 ‚Äì present    \\nBachelor Of Science in Computer Science  \\nGraduation: (July 2026 ) \\n   \\n‚óè Predicted Grade: First Class  \\n‚óè Current CG PA: 3.92/4.0   \\n‚óè Current Semester: 4 th \\n   \\nTechnical Skills    \\n \\n‚óè Programming Languages: Python, Java, C++, C , C#.net framework  (Frontend , \\nBackend ), Html , CSS, Java Script  \\n‚óè Technologies: Machine Learning , Dee p Learning , Natural Language Processing \\n(NLP)   \\n \\nPROJECTS     \\n \\nAs part of my dissertation, I have undertaken and successfully completed several projects \\nthat demonstrate my proficiency in various programming languages, frameworks, and \\nmachine learning models. These projects include:  \\n \\n \\n‚Ä¢ Real -Time Hand Sign Detection Model  \\nCreated a real -time hand sign detection model utilizing the YOLO (You Only Look Once) \\nalgorithm. This project focused on developing an accurate and responsive system for \\nrecognizing hand gestures in real -time, which can be applied in various assistive \\ntech nologies.  \\n‚Ä¢ Handwritten Image Classification Neural Network Model  \\nBuilt a neural network model for classifying handwritten images. This project involved \\npre-processing image data, designing and training the neural network, and achieving \\nhigh accuracy in recognizing handwritten digits and letters.  \\n‚Ä¢ Afzal Electronic Store Application  \\nDeveloped an electronic store application using the C#.NET framework. This project \\ninvolved designing a user -friendly interface, implementing secure payment systems, and \\nintegrating database management for efficient inventory tracking.  \\n‚Ä¢ Car Rental System  \\nDesigned and implemented a car rental system using Java. This project included the \\ndevelopment of a comprehensive booking system, user authentication, vehicle tracking, \\nand maintenance scheduling features, ensuring a seamless user experience.  \\n‚Ä¢ Neural Network Model Using Plain Python  \\nDeveloped a complete neural network model from scratch using plain Python. This \\nproject emphasized understanding the fundamental workings of neural networks, \\nincluding forward propagation, backpropagation, and gradient descent, without relying \\non high -level libraries.  \\nThese projects have not only enhanced my technical skills but also provided me with \\nvaluable experience in problem -solving, project management, and the application of \\ntheoretical knowledge to practical scenarios.  \\n    \\nACHIEVEMENTS  \\n    \\n‚óè Top Achiever Grant  for outstanding academic performance (2022 -2023)  \\n‚óè Got Invited to Telenor H Q | Gulberg Islamabad  for Amazing WorkS hop \\n \\n'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_chunks = TokenTextSplitter(chunk_size=7, chunk_overlap=0).split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Abdul Sami\\nRaw',\n",
       " 'alpindi, Pakistan\\n',\n",
       " '‚ôÇphone+92-316',\n",
       " '-5563797 /envel',\n",
       " '‚å¢perajasami',\n",
       " '408@gmail.com /linked',\n",
       " 'inlinkedin.com/in',\n",
       " '/abdulsami /github',\n",
       " 'github.com/abduls',\n",
       " 'ami55\\nSUMMARY']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_chunks[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "170"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Groq model (Llama 3 8b) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\Desktop\\RAG\\Doc_yt_ChatBot\\doc-chat-env\\Lib\\site-packages\\langchain_groq\\chat_models.py:361: UserWarning: WARNING! top_p is not default parameter.\n",
      "                    top_p was transferred to model_kwargs.\n",
      "                    Please confirm that top_p is what you intended.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "llm = ChatGroq(model=\"llama3-8b-8192\",\n",
    "               temperature=0.4,\n",
    "               max_retries=2,\n",
    "               max_tokens=700,\n",
    "               top_p = 0.8, \n",
    "               streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(model=\"llama3-8b-8192\",\n",
    "               temperature=0.4,\n",
    "               max_retries=2,\n",
    "               max_tokens=700,\n",
    "               model_kwargs={\"top_p\":0.8, \"presence_penalty\" : 0.8},\n",
    "               streaming=True,\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Let me count them for you!\\n\\nThere are 3 \"R\"s in the word \"strawberry\".', additional_kwargs={}, response_metadata={'finish_reason': 'stop'}, id='run-0005d653-e6f4-46da-a003-e95f32900ac4-0', usage_metadata={'input_tokens': 26, 'output_tokens': 23, 'total_tokens': 49})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from langchain.prompts import ChatPromptTemplate\n",
    "llm.invoke(\"how many 'r' are there in the word 'strawberry' ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's an implementation of Tip #1:\n",
      "\n",
      "Dear [Hiring Manager],\n",
      "\n",
      "I am excited to apply for the position of developing a deep learning model to predict images in the CIFAR-10 dataset. With extensive experience in neural networks and hyperparameter tuning, I am confident in my ability to deliver a high-quality solution that meets your requirements.\n",
      "\n",
      "Throughout my career, I have had the opportunity to work with various deep learning frameworks, including TensorFlow and PyTorch, and have successfully implemented neural networks for image classification, object detection, and segmentation tasks. My experience with the CIFAR-10 dataset is particularly relevant to this project, as I have worked with it in the past to develop and fine-tune convolutional neural networks (CNNs) for image classification.\n",
      "\n",
      "In my previous projects, I have demonstrated my expertise in hyperparameter tuning, using techniques such as grid search, random search, and Bayesian optimization to optimize model performance. I am well-versed in the importance of hyperparameter tuning in deep learning and understand the impact it can have on model accuracy and efficiency.\n",
      "\n",
      "I am particularly excited about the opportunity to apply my skills and experience to this project, as I believe that a CNN or YOLO model would be a great choice for this task. My experience with YOLO has shown me the potential of this model for object detection tasks, and I am confident that it could be adapted for image classification in the CIFAR-10 dataset.\n",
      "\n",
      "I would like to highlight that my previous project on Hand Sign detection using YOLO model demonstrates my ability to adapt and apply deep learning models to new tasks. I am confident that my skills and experience make me an ideal candidate for this project, and I look forward to the opportunity to discuss my qualifications further.\n",
      "\n",
      "Thank you for considering my application.\n",
      "\n",
      "Sincerely,\n",
      "[Your Name]\n"
     ]
    }
   ],
   "source": [
    "message = [\n",
    "    (\"system\",\"You are a expert Proposal Writer and Proposal Reviewer, and you will just tell me about that does it wants\"),\n",
    "    # (\"human\",f\"Make me a summary for this content \\n {text}\")\n",
    "    (\"human\",\"\"\"\n",
    "        Tip # 1 : Highlight your experience with neural networks and hyperparameter tuning to show your qualifications for the job.\n",
    "     \n",
    "     Implement this tip.\n",
    "     Hi there, I have read your job detalis and form which I have find out that you needed a deep learning model that can predict the images in the CIFAR-10 dataset. I have work a lot with the CIFAR-10 dataset( Its a great open source dataset with 10 different categories). I have work with it, In my past experience I have made some projects using the CNN and its a really great choice if we use CNN for this as these are images right, btw we can also use YOLO model for it as well, I have build a Hand Sign detection using YOLO model, and I gurentee you that your project won't be going to waste. \"\"\")\n",
    "]\n",
    "\n",
    "print(llm.invoke(message).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import voyageai\n",
    "from langchain.embeddings.base import Embeddings\n",
    "\n",
    "# pass the langchain embedding as qdrant won't gonna accept it, this will create a langchian embedding wrapper\n",
    "class VoyageEmbeddings(Embeddings):\n",
    "    def embed_documents(self, texts):\n",
    "        voyage_client = voyageai.Client(api_key=os.getenv(\"VOYAGEAI_API_KEY\"))\n",
    "        # Embedding all texts\n",
    "        results = voyage_client.embed(texts, model=\"voyage-2\", input_type=\"document\")\n",
    "        return results.embeddings\n",
    "\n",
    "    def embed_query(self, text):\n",
    "        # Reusing embed_documents for a single query\n",
    "        return self.embed_documents([text])[0] \n",
    "    \n",
    "voyageai_obj = VoyageEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\Desktop\\RAG\\Doc_yt_ChatBot\\doc-chat-env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "gemini_embeddings = GoogleGenerativeAIEmbeddings(google_api_key=os.getenv(\"GEMINI_API_KEY\")\n",
    "                                                 , model=\"models/text-embedding-004\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# makig a vector store in memeory\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import VectorParams, Distance\n",
    "\n",
    "client = QdrantClient(\":memory:\") # initalize the qdrant client\n",
    "\n",
    "client.create_collection( # creating the collection in the qdrant client\n",
    "    collection_name=\"pdf\",\n",
    "    vectors_config=VectorParams(size=768 , distance=Distance.COSINE)\n",
    ")\n",
    "\n",
    "vector_store = QdrantVectorStore( # creating the vectorstore from collection\n",
    "    client=client,\n",
    "    collection_name=\"pdf\",\n",
    "    embedding=gemini_embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pdf'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# client_check = QdrantClient(\":memory:\")\n",
    "collection = client.get_collections().collections\n",
    "# if collection:\n",
    "#     print(\"abc\")\n",
    "\n",
    "collection_name = collection[0].name\n",
    "collection_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading Qdrant vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = QdrantVectorStore(\n",
    "    client=client,\n",
    "    collection_name=collection_name,\n",
    "    embedding=gemini_embeddings\n",
    ")\n",
    "\n",
    "# vector_store_renew.similarity_search(\"what is happiness\", k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'pdf file'}, page_content='asdhfashflksdjhf  adjfjkjdsafhd fsd fjsd hfdshf kjdajhfweohfaowienfwea adsncjsda chf')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.docstore.document import Document # this is how you can create a document of a text and add your own metadata\n",
    "\n",
    "text_doc = Document(\n",
    "        page_content=\"asdhfashflksdjhf  adjfjkjdsafhd fsd fjsd hfdshf kjdajhfweohfaowienfwea adsncjsda chf\", \n",
    "        metadata={\n",
    "            \"source\":\"pdf file\"\n",
    "        }\n",
    "    )\n",
    "text_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['54cb7ba8-bda0-4210-a6bd-406cd4d97beb',\n",
       " 'cc6617b3-e746-481a-82a1-397d9e144a0b',\n",
       " '74d05257-3939-48d9-8ca9-e794c0f543cb',\n",
       " '8436fa97-ee79-4e45-a374-e57689386280',\n",
       " '0d6430c8-52a4-45b7-851e-dac972453f73',\n",
       " '4fcd6625-d75d-4eca-9f4d-660daf2044c0',\n",
       " '81c61af6-1cda-4321-a8b5-02537b970f02',\n",
       " 'a917a3cb-9603-4080-9cc1-2c26126c6f74',\n",
       " '1ddecf42-9402-4622-b203-d012d2071a93',\n",
       " 'c65024c3-324f-4b85-b862-1763a6d5338e',\n",
       " '0a6c7990-f20b-4d46-9ff0-63b74f92db52',\n",
       " '646bfa2b-5582-436d-a236-a8c3abefabf0',\n",
       " '9d77feb6-0767-4ba1-b8fa-855076348233',\n",
       " '88fc9428-fcec-49f5-aba9-5c231c5192b3',\n",
       " '43361740-495b-47a6-8c71-793b594ca76d',\n",
       " 'c7a3d95a-9898-4d37-8ea8-cf052f172543',\n",
       " '38ed4ce0-b6b2-494a-8c58-dd07947a212b',\n",
       " 'ca7ac183-633d-4b89-99f6-7eb6f1aa3b7c',\n",
       " 'b0130297-d8f8-47e0-8e84-ca629a9dce59',\n",
       " 'e03e462a-a34e-4b9a-a42f-813ed3726083',\n",
       " 'e3f362e4-b8d3-4a59-b5fd-2150bfb70540',\n",
       " '63ca0a1f-7a8d-47cb-ab4d-8ddb4196fe44',\n",
       " 'b354793e-fe41-4451-b1a4-2e257483daad',\n",
       " '2d1731d4-7681-469c-b137-bb4ae1646d1f',\n",
       " '6f098f08-18cc-48c0-b0eb-8a580f34beed',\n",
       " 'd1eac09b-f335-4cfa-afb7-fe6199fb7e6a',\n",
       " 'b5dcdbc8-2150-4712-a229-1d4821744d3b',\n",
       " '3cb51740-1359-420f-b31e-e9bdaf48db54',\n",
       " '8c66822f-308e-403c-9ee0-4d0c6e9737c3',\n",
       " '4eef3ecc-f290-4efe-b839-2702c762f12e',\n",
       " '0edc927b-de78-46fe-a186-0b180f244e09',\n",
       " '506d7540-7b1d-4715-8ab8-e4c11d5e6939',\n",
       " '5e172584-1bd7-418b-930b-50837badc283',\n",
       " '53997298-0f23-4f0e-abf0-03ad49babb39',\n",
       " '42c00488-ee41-4bed-ad83-d098c3b6cf13',\n",
       " '29b2d7ed-c9d3-49ad-8b55-1c3a7c785e4e',\n",
       " '21220851-40eb-4960-8942-9addc1f327e2',\n",
       " '3e441b83-d5cb-43e5-b738-8d75450f5aa4',\n",
       " '4b6cb773-fe15-49ea-a358-78ecd53f210e',\n",
       " '6c41a705-d2d7-4593-86e8-1f876d608379',\n",
       " '7e10b321-6084-4a50-85cc-cace15db3baa',\n",
       " '6a4ce1d7-30cf-4739-a7be-645d06597a86',\n",
       " 'ebb42d32-a67e-4d22-8a62-0e7fd151eed4',\n",
       " '801d6496-3e45-4ca2-a7b3-b782de144d4b',\n",
       " '5d4df1f4-a145-4ece-8db4-938b23de12df',\n",
       " '81591626-496b-4070-8bfb-3c8cd35f6e46',\n",
       " 'f461eaf8-34ba-44f4-be8d-518ed15de153',\n",
       " '6664efbb-c69c-46de-845b-f3d9ee477f92',\n",
       " 'f27ddbd0-bc7f-4cf4-b713-f14b59d58586',\n",
       " '294a9e59-5633-4147-a304-ce55a31f872a',\n",
       " '8adcc4ef-7f41-4d6e-bbbd-d88e66c43afd',\n",
       " '72e36ed6-5b4f-42b2-abd0-8868fce42857',\n",
       " 'eca88fbc-5ffc-4e31-963a-425d3a7567a7',\n",
       " '783f6b8b-f183-472c-a441-b99785b579f2',\n",
       " '9e569719-4a73-422a-b7d1-bc84e0e6eeed',\n",
       " '214a9b1a-5120-484d-ab2c-4807f1cc679f',\n",
       " '7593200e-ad01-42db-bac8-517dfb80ec58',\n",
       " '5dce55a9-b528-46cb-81be-9b48c3a4b5d4',\n",
       " 'f85aff0a-b9ef-4c35-91b5-44b3464fc680',\n",
       " 'edb858cf-69b1-4515-89f6-5f234bf58f4a',\n",
       " '6be6b467-0f3c-4cf2-aa97-c347b2d713f8',\n",
       " 'b4e8821c-9ce3-4d84-a215-2c724b576870',\n",
       " 'ef0b30d9-4be1-433d-a39f-1f4b06c6259b',\n",
       " '03793969-8fee-4252-b330-2285eb179492',\n",
       " 'b2769721-3c70-41ec-a126-ad64d5d9a803',\n",
       " 'f41a20d4-6ebd-4572-9e27-50b4c0a8bf12',\n",
       " '3df08dbb-6a75-4597-9eb1-26f43cccd3a2',\n",
       " '74444446-8dd0-489d-b615-1196115f9d26',\n",
       " '25d4fd0a-ae8f-469a-b03c-a5ef461698f8',\n",
       " '5b78ff48-7bb0-46fe-ac37-39652bbdb281',\n",
       " '86b98665-01f6-4c3b-ae1f-9d6235656773',\n",
       " '564fd081-e072-43c3-a0d5-e7554f904c9b',\n",
       " '1fcf49e2-d766-43ce-a663-1d576d21c40c',\n",
       " '35249494-c313-4be3-8bb0-74e4214adafa',\n",
       " '7ef25c20-e897-4c7a-8cc4-cbb2f7223183',\n",
       " '3ecb01ea-d894-4550-ade8-3fbcbb63e27d',\n",
       " 'a5b104ec-d442-4352-9305-8df3db94d882',\n",
       " '3accebd9-95d1-4a40-b755-0da646754a1a',\n",
       " '3de85e85-aa2e-4c2c-b9ed-503a7a0f13f3',\n",
       " '3b8fce8e-0122-4d0f-8520-57ca835f58c9',\n",
       " '23cbc128-4b35-4c15-b353-25733038faea',\n",
       " '777906db-b8c8-4197-9eaf-478094dd6a43',\n",
       " 'a138730a-8b14-40f6-82ab-6a6b74502a31',\n",
       " '4491b24a-7ffa-402f-8801-ced133e37bac',\n",
       " '8f53d71d-4652-41c8-acec-44b7b21ac63b',\n",
       " '5712a85a-1783-4ef2-874f-d33da64f0b9a',\n",
       " 'de86e1a6-b7c3-4469-8a3e-b248cc07d595',\n",
       " '940c91be-b9f8-4007-a691-b6c1e1e2d5c3',\n",
       " 'bb4af111-a22b-4409-9e4b-e498a03f04aa',\n",
       " 'fef99da1-2827-4aff-9ee9-094000e7e185',\n",
       " 'ad67395f-0dc0-42aa-b785-3154bc0e6d44',\n",
       " '9f6ff9f6-d792-4fb2-92e5-f038a0915931',\n",
       " 'd51545da-7a09-4b06-86f1-1a45934a5a31',\n",
       " 'ba6265f8-ccd3-406a-aada-b77fce99f553',\n",
       " '81cf2b38-8494-4466-a869-fe909b2b7d28',\n",
       " '263a8aba-2fe8-42cd-aa57-07b38ebe01ef',\n",
       " '3c1dfe48-e845-48f1-97d8-138e53677e62',\n",
       " '62baed46-d606-44c7-9589-6f57fb2bf24b',\n",
       " '63ee260f-bd30-4414-b3ec-e210ec12d38e',\n",
       " 'e3b7a334-8589-464f-bf93-6a4a9aaeefe9',\n",
       " '74919b6d-257d-4ba7-8a93-650727469902',\n",
       " 'a1e0522e-139f-4823-b573-8994a340ce73',\n",
       " 'eb3cf91d-ea99-469e-ac64-2053d0d3d65e',\n",
       " 'dc00329e-2448-4c29-9ad3-17119af9ab40',\n",
       " 'a6bb086d-44c3-4b47-9717-680a39a60464',\n",
       " '48ec4090-0d23-4d55-831b-7c6919bc2f08',\n",
       " '2e151e76-b44e-4840-8913-aafe96319816',\n",
       " '5e3af43d-955a-4884-b1ef-c426bd1577e8',\n",
       " '6900bf0c-60ab-406a-9ee7-3c516730b34f',\n",
       " '15caee1f-6d7c-44eb-aae2-28d2b235753b',\n",
       " 'f8eb6191-5d67-48b8-97dd-de7200b77ea5',\n",
       " '52cd08ce-6cf7-47b9-a1e5-a1ca94956d1b',\n",
       " '9830b1a3-ee2b-4191-8f75-8d622a6aae75',\n",
       " '11862b4d-0aa6-4483-b13e-0fe0973ab5d2',\n",
       " '6151a4c0-e8c8-443f-b3d3-f2b2c3a97d70',\n",
       " '200106aa-ffbb-4fad-ae06-e87497ff0dcb',\n",
       " '5897e6cb-b950-4c02-8576-15ea28ea524a',\n",
       " '3c15f46a-bbba-474e-b417-108a3eb1b95e',\n",
       " '5561649a-60c2-4004-94d7-900c9e28d824',\n",
       " '47f3f371-dab2-4e4c-8dd5-e9951b7aa4ff',\n",
       " '47c75b8d-0cb9-42bc-9e43-0c8912e1dfff',\n",
       " 'a712ae28-71e1-453e-944f-aacf2f8843d9',\n",
       " '3ab23132-ad1c-463e-bec8-7595285b1b70',\n",
       " 'f8168af3-6b7e-446b-a724-0f0537e9fdcc',\n",
       " '384b5d4c-b1d6-484a-87ed-7e67a528e527',\n",
       " 'b3c029d6-97a4-4230-8453-ebcd838869c1',\n",
       " 'a7a25848-a3dd-488f-9e22-ec92327cfaa3',\n",
       " '0b6a6856-9b3c-4a3f-8824-5417cdf13888',\n",
       " 'e4b0326e-f2bf-4a25-b488-bcd140890218',\n",
       " '421e859a-90ef-4241-a241-3d8dbe63532a',\n",
       " '31ba7c51-41da-4d72-a498-729e3a5f507c',\n",
       " 'bfe70170-04d8-4572-96f4-e29a1bcdd092',\n",
       " '081b31cb-2219-4d8d-a34c-337bd6014752',\n",
       " 'c4756cbe-c4d6-46f6-bd8e-654d8cad11fb',\n",
       " 'e389fd6d-fd30-4c8e-a397-b717eb9deadb',\n",
       " '847265a5-a030-4a68-aba2-0132cf3c98a8',\n",
       " 'e9ff2afa-89aa-4cba-a91d-53ab958f6d8a',\n",
       " '9273d5b0-713a-46c7-abea-6832e14eb089',\n",
       " '5c914edb-464b-42bd-b920-b5f4c6368ea1',\n",
       " '71497985-1fb2-4d44-9b33-bbbb45a428d7',\n",
       " '869be722-855a-4816-90c7-7de309ac1527',\n",
       " 'e27d136b-0c14-4b01-b004-c8b8ba0cd4e2',\n",
       " '7dc13b56-778c-4650-8b38-038153660c78',\n",
       " '1b683858-7bd4-41ce-9021-9bcaf0b7bac5',\n",
       " '0b2eb343-4858-44d3-88ee-cbe18cd93ce2',\n",
       " 'd6d2d2c7-b2ce-4983-bad3-0fdf8c562c79',\n",
       " '18caef68-2b34-44e8-9747-8c69634bd1eb',\n",
       " 'aea292e7-7448-4dc0-ad08-418c31353c52',\n",
       " '9b8632cf-6e4b-495a-a913-2b6d868deb08',\n",
       " 'dbb7c4f2-da5d-4bef-abfe-741eaa3482d0',\n",
       " '9bf59690-13f1-4366-b6d5-f821930e06be',\n",
       " 'f23b3a5b-30db-438e-a07b-53f0cc5115ea',\n",
       " '38fc78fa-b916-4253-b2a9-5451dfd33e53',\n",
       " '6ce87eed-3343-40a8-9b67-cbcf6a0b3a41',\n",
       " 'df42c996-f6c1-4cce-86c5-3a8c852bfbea',\n",
       " '903cfc18-d64f-414e-9a2c-8e3ffc4f7ad1',\n",
       " 'd1cb2cb0-ea75-49ba-b7c8-8873ce0bb766',\n",
       " '326d8e04-9e60-460f-a80e-dbfe7fe99163',\n",
       " '19eff92c-758d-4e44-9be3-60d173010945']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from uuid import uuid4 # universal unique identifier use for making unique ids\n",
    "\n",
    "# uuids = [str(uuid4()) for _ in range(len(chunks))] # making unique ids for each chunks\n",
    "# db=vector_store.add_documents(documents=chunks, ids=uuids)\n",
    "\n",
    "# adding more data to see if it overwites or not\n",
    "\n",
    "ids = [str(uuid4()) for _ in range(len(chunks_new))]\n",
    "vector_store.add_documents(documents=chunks_new, ids=ids) # this will return you the uuid for each chunk\n",
    "\n",
    "# yes this works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_new = \"what is happiness\"\n",
    "results = vector_store.similarity_search(query_new, k=2)\n",
    "\n",
    "# for result in results:  \n",
    "#     print(result.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'c:\\\\Users\\\\HP\\\\OneDrive\\\\Documents\\\\Books\\\\The Art of Being ALONE Solitude Is My HOME, Loneliness Was My Cage.pdf', 'page': 86, '_id': '869be722-855a-4816-90c7-7de309ac1527', '_collection_name': 'pdf'}, page_content='In the past year, I have  learned three new skills. The\\nrecent one was something  that I wanted to learn since I was\\n16.\\xa0 I started learning ‚Äòcrocheting‚Äô  almost a few months\\nback. Now that I know it, I feel super excited every day to\\nmake something new. I keep watching YouTube videos on\\nhow to crochet a bag or save cute crochet tops on Pinterest.\\nIt all feels exciting. I feel that I have a life beyond my work.\\nWith every new thing I make, I feel like I am growing. It feels\\nexciting to know that I am learning something that I always'),\n",
       " Document(metadata={'source': 'c:\\\\Users\\\\HP\\\\OneDrive\\\\Documents\\\\Books\\\\The Art of Being ALONE Solitude Is My HOME, Loneliness Was My Cage.pdf', 'page': 72, '_id': '3c15f46a-bbba-474e-b417-108a3eb1b95e', '_collection_name': 'pdf'}, page_content='had no means to pay my bills. That was the time when all\\nmy college mates were earning great money , having\\nvacations, and buying stuÔ¨Ä with their own money. I was\\njealous and I just wanted to prove to myself that I am\\nmoving forwar d.\\nSo, I started writing on Medium which is a platfor m for\\nwriters. I didn‚Äôt have any hopes from Medium. I just wanted\\nto prove to myself that I am doing something *at least.* I\\nhad the goal of writing one article every day. 10 months\\nlater, I had 10,000 followers. And that wasn‚Äôt enough. I'),\n",
       " Document(metadata={'source': 'c:\\\\Users\\\\HP\\\\OneDrive\\\\Documents\\\\Books\\\\The Art of Being ALONE Solitude Is My HOME, Loneliness Was My Cage.pdf', 'page': 21, '_id': '506d7540-7b1d-4715-8ab8-e4c11d5e6939', '_collection_name': 'pdf'}, page_content='I am not a love expert. God forbid. But I know one thing\\nthat you fall in with someone when you get to know them.\\nIsn‚Äôt it?\\nSo, let‚Äôs Ô¨Ånd YOU so that you can fall in love with the real\\nYOU. Shall we?'),\n",
       " Document(metadata={'source': 'c:\\\\Users\\\\HP\\\\OneDrive\\\\Documents\\\\Books\\\\The Art of Being ALONE Solitude Is My HOME, Loneliness Was My Cage.pdf', 'page': 5, '_id': '0d6430c8-52a4-45b7-851e-dac972453f73', '_collection_name': 'pdf'}, page_content='Acknowledgment\\nThis book wouldn‚Äôt have been possible withou t my\\nsupport. I know it‚Äôs a weird acknowledgment because most\\npeople credit their success to someone they love the most.\\nWell, the thing is, I love myself the most for standing by\\nmyself when I couldn‚Äôt Ô¨Ånd anyone. When no one was there\\nand I was sur rounded by self -doubts, uncertainty, and a dark\\nfutur e, I didn‚Äôt give up on myself; for that, I want to thank\\nmyself . I want to thank myself for Ô¨Åghting hard against my\\nown mind and doubts. I want to thank myself for doing\\neverything it took to transfor m my dr eams into my r eality .\\nI also want to thank my Instagram followers & Medium\\nreaders who have shower ed immense love on all my articles\\n& posts. A big thanks for making me feel so loved and\\nconÔ¨Ådent. W ithout my r eaders, I am anyway, nothing.')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Tell me its projects\"\n",
    "results = vector_store.similarity_search(query, k=4)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "machine learning models. These projects include:\n",
      "These projects have not only enhanced my technical skills but also provided me with \n",
      "valuable experience in problem -solving, project management, and the application of \n",
      "theoretical knowledge to practical scenarios.  \n",
      "    \n",
      "ACHIEVEMENTS  \n",
      "    \n",
      "‚óè Top Achiever Grant  for outstanding academic performance (2022 -2023)  \n",
      "‚óè Got Invited to Telenor H Q | Gulberg Islamabad  for Amazing WorkS hop\n",
      "and maintenance scheduling features, ensuring a seamless user experience.  \n",
      "‚Ä¢ Neural Network Model Using Plain Python  \n",
      "Developed a complete neural network model from scratch using plain Python. This \n",
      "project emphasized understanding the fundamental workings of neural networks, \n",
      "including forward propagation, backpropagation, and gradient descent, without relying \n",
      "on high -level libraries.\n",
      "Built a neural network model for classifying handwritten images. This project involved \n",
      "pre-processing image data, designing and training the neural network, and achieving \n",
      "high accuracy in recognizing handwritten digits and letters.  \n",
      "‚Ä¢ Afzal Electronic Store Application  \n",
      "Developed an electronic store application using the C#.NET framework. This project\n",
      "\n"
     ]
    }
   ],
   "source": [
    "retrieved_data = \"\"\n",
    "for result in results:\n",
    "    retrieved_data+= result.page_content + \"\\n\"\n",
    "print(retrieved_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on your user input \"Tell me its projects\", I will summarize the document and provide the information about the projects mentioned in the document.\n",
      "\n",
      "Here are the projects mentioned in the document:\n",
      "\n",
      "1. Neural Network Model Using Plain Python: Developed a complete neural network model from scratch using plain Python. This project emphasized understanding the fundamental workings of neural networks, including forward propagation, backpropagation, and gradient descent, without relying on high-level libraries.\n",
      "2. Built a neural network model for classifying handwritten images: This project involved pre-processing image data, designing and training the neural network, and achieving high accuracy in recognizing handwritten digits and letters.\n",
      "3. Afzal Electronic Store Application: Developed an electronic store application using the C#.NET framework.\n",
      "\n",
      "These are the projects mentioned in the document. Let me know if you need any further information!\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "# message = ChatPromptTemplate.from_messages(\n",
    "#     [\n",
    "#         (\"system\",\"You are a helpful document reviewer, you will recieved a document and you will have to tell just what is in the document. base on the given user input\"),\n",
    "#         (\"human\",\"user input: {query}\\nAnd here is the document {doc}\")\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "message = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are great summary maker, you will recieved a document and you will have to summarize those docs,base on the given user input but lose any info base on the user query\"),\n",
    "        (\"human\",\"user input: {query}\\nAnd here is the document {doc}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = message | llm | StrOutputParser()\n",
    "\n",
    "print(chain.invoke({\"query\":query, \"doc\":results}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "doc-chat-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
